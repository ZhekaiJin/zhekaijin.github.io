<!DOCTYPE HTML>
<html>
	<head>
		<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
		<title>Zhekai Jin - Cooper Union</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!-- user-scalable=no -->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!-- WHERE YOU CAN ADD TRACKING CODE  -->
				<script async src="https://www.googletagmanager.com/gtag/js?id=UA-131804405-1"></script>
				<script>
				  window.dataLayer = window.dataLayer || [];
				  function gtag(){dataLayer.push(arguments);}
				  gtag('js', new Date());
				  gtag('config', 'UA-131804405-1');
				</script>
	</head>
	<body class="is-preload">
		<!-- Header -->
			<header id="header">
				<div class="inner">

					<a href="#" class="image avatar"><img src="images/avatar.png" alt="" /></a>
					<h1><strong>Zhekai(Scott) Jin</strong><br></h1>
					<h1 style="margin-top: 0.4em"><sup><a href="mailto:jin4@cooper.edu" class="icon fa-envelope">&nbsp;&nbsp;jin4@cooper.edu</a></sup><br></h1>
					<h1><sup><a href="https://www.linkedin.com/in/scott-zhekai-jin-196aa1b1" class="icon fa-linkedin">&nbsp;&nbsp;LinkedIn</a></sup>&nbsp;&nbsp;&nbsp;&nbsp;<sup><a href="https://www.facebook.com/zhekaiJINScott" class="icon fa-facebook">&nbsp;&nbsp;Facebook</a></sup></h1>
					<h1><sup><a href="docs/Jin_Zhekai_Resume.pdf" class="icon fa-briefcase">&nbsp;&nbsp;Resume</a></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup><a href="https://github.com/zhekaijin" class="icon fa-github">&nbsp;&nbsp;Github</a></sup></h1>
					<h1><sup><a href="docs/Jin_Zhekai_Research.pdf" class="icon fa-android">&nbsp;&nbsp;Experience</a></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup><a href="docs/Jin_Zhekai_CV.pdf" class="icon fa-suitcase">&nbsp;&nbsp;C.V.</a></sup></h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">
				<!-- One -->
					<section id="one">
						<h2>About</h2>
						<p>I'm a first year graduate student at <a href="https://www.cmu.edu/">Carnegie Mellon University</a> where I am pursuing a M.S. in <a href="https://mrsd.ri.cmu.edu/">Robotic Systems Development (MRSD)</a>.
							 My interest lies in Robotics, Perception, Motion Planning, Distributed Embedded Systems, Machine Learning and Artificial Intelligence.
						</p>
						<hr/>
						<br>
						<h2>News</h2>
						<ul>
							<li> Working on research the deployment of DJI's newly developed <a href="https://www.livoxtech.com/mid-40-and-mid-100">Livox Lidar</a> to indoor SLAM problem against the aggressive motion problem at <a href="http://biorobotics.ri.cmu.edu/index.php">Biorobotics Lab</a> at Carnegie Mellon University
                  with <a href="https://www.cs.cmu.edu/~./choset/">Dr. Howie Choset</a>.
							</li>
							<li>  My first-authored paper <a href="docs/IEEE_Region_One_Submission.pdf">"A MultiSensor Data Fusion Approach For Simultaneous Localization And Mapping"</a> was accepted by the <a href="https://www.itsc2019.org/">IEEE Intelligent Transportation Systems Conference (ITSC)</a> to be held in New Zealand.</li>
							<li>  The same paper won the 1st Place in the IEEE Region 1 2019 Student Papers Competition, and our team gave an oral presentation at the <a href="https://www.ieee.org/membership/students/student-conferences.html">2019 IEEE Region I Annual Student Conference (StuCon' 19)</a>.</li>
							<!-- Eta Kappa Nu -->
							<!-- <li> I got selected into Cooper Union's chapter of <a href="https://hkn.ieee.org/">Eta Kappa Nu</a>, the electrical engineering honor society.</li> -->
							<li> I started reasearch regarding the topic of <a href="http://www.cs.columbia.edu/~ansaf/cing/PTB/index.html">Prediction of Preterm Birth</a> with advanced Machine Learning techniques
								   at <a href="https://engfac.cooper.edu//araja/506">Distributed Intelligent Agents Lab (DIAL)</a>
								   with <a href="https://engfac.cooper.edu//araja">Dr. Anita Raja</a>.
							</li>
							<!-- <li> Working on reasearch topic regarding Multisensor Data Fusion with Lidar and Stereo Camera, advised by
								<a href="http://faculty.cooper.edu/sable2/">Dr. Carl Sable</a>,
								<a href="https://engfac.cooper.edu/nshlayan">Dr Neveen Shlayan</a>, and
								<a href="https://engfac.cooper.edu/dluchten">Dr. Dirk Luchtenburg</a>
 								, Manuscirpt in preparation</li> -->
							<!-- <li> I got selected into Cooper Union's chapter of <a href="https://www.tbp.org/home.cfm">Tau Beta Pi</a>, the engineering honor society.</li> -->
							<li> I joined <a href="https://momenta.ai/en">Momenta.ai</a> as a Lidar Perception research intern working on Object Detection & Tracking, Semantic Segmentation & Ground Detection. </li>
							<li> I joined <a href="http://www.didi-labs.com/">DiDi Lab</a> as an Algorithm Research Intern working on Intelligent Dispatching Solution </li>
							<li> I initiated <a href="https://engfac.cooper.edu/nshlayan/689">Autonomy Lab</a> with <a href="https://cooper.edu/academics/people/neveen-shlayan">Dr. Neveen Shlayan</a> as the first Robotics Lab in Cooper Union.</li>
							</li>
						</ul>

					<hr/>
					<br>
					<h2>Recent Work</h2>
						<!-- 3D reconstruction -->
						<div style="width: 100%; height: 16em">
							<div style="border-radius: 0.35em; float: left; width: 31%; height: 9.5em; margin-right: 3%; background: rgba(45,44,45,1);">
								<video width="100%" playsinline muted autoplay loop style="border-radius: 0.35em; height: 9.5em; opacity: 0.8;">
								  <source src="videos/3D_reconstruct.mp4" type="video/mp4">
								</video>
							</div>

							<div style="border-radius: 0.35em; float: left; width: 31%; height: 9.5em; margin-right: 3%; background: rgba(48,48,48,1);">
								<video width="100%" playsinline muted autoplay loop style="border-radius: 0.35em; height: 9.5em; opacity: 0.8;">
								  <source src="videos/lidar_mapping.mp4" type="video/mp4">
								</video>
							</div>

							<div style="border-radius: 0.35em; float: left; width: 31%; height: 9.5em; margin-right: 1%; background: rgba(0,43,54,1);">
								<video width="100%" playsinline muted autoplay loop style="border-radius: 0.35em; height: 9.5em; opacity: 0.8;">
								  <source src="videos/WiFiTracking.mp4" type="video/mp4">
								</video>
							</div>


							<div style="float: left; width: 31%; margin-right: 3%; font-size: 0.8em; line-height: 1.5em; margin-top: 1em;"><center>Stereo 3D Reconsturction</center>"How does the robot perceive the world with dynamics and semantics?" <a href="https://p3d.in/x1fMl+load+spin/"> &nbsp;&nbsp;Model</a> </div>
							<div style="float: left; width: 31%; margin-right: 3%; font-size: 0.8em; line-height: 1.5em; margin-top: 1em;"><center>Fast 2D Lidar Mapping</center>"How can robots perform online learning and active perception?" <a href="https://github.com/ZhekaiJin/the-Cooper-Mapper/">Project</a> &nbsp;&nbsp;<a href="videos/lidar_mapping.mp4">Video</a></div>
							<div style="float: left; width: 31%;font-size: 0.8em; line-height: 1.5em; margin-top: 1em;"><center>Real-time WiFi Tracking</center>"How to track people's positions with their phones' WiFi or Bluetooth?" <a href="http://www.utrc2.org/research/projects/real-time-estimation-transit-origin">Project</a> </div>
							<!-- <div style="float: left; width: 23%; font-size: 0.8em; line-height: 1.5em; margin-top: 1em;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AI Checker with Minimax<br>"Can you beat a robot player in a zero-sum game like Checker?" <a href="https://github.com/ZhekaiJin/AI-Checker/">Project Link</a> &nbsp;&nbsp;<a href="videos/checker.mp4">Video</a> </div> -->

						</div>
					<hr>
					<br>
					<h2>Research</h2>
					<p>I work on robotics and autonomous driving. I envision an end-to-end system take rich 3D data and perform efficent 3D scene understanding. I believe the future lies in lifelong learning and long-term SLAM. </p>
					<div class="row">
						<article class="12u 12u$(xsmall) work-item">
							<a href="https://github.com/ZhekaiJin/the-Cooper-Mapper" class="image fit thumb left"><img src="images/projects/car.jpg" alt="" /></a>
							<h3 style="margin-left: 43%">The Cooper Mapper: Cost-friendly Autonomous driving Research Platform for MultiSensor Data Fusion, SLAM, etc.</h3>
							<p style="margin-left: 43%">
								To make robots generally useful in the broader world, in applications like autonomous driving, urban search and rescue, AI-assisted precision agriculture, etc., they need to operate in large, three dimensional and potentially unstructured environments.
                Therefore, they need general algorithms for mapping, localizing, planning and exploring that work just about anywhere.
                In this work, we are working toward a general Simultaneous Localization and Mapping (SLAM) solution that fully leverages the advantages of Lidar and Stereo Camera,
                has constant computation time (real-time) and linear in storage space, and utilizes efficient map representation which will be fully 3D and capable of representing arbitrary 3D geometry at a proper level of resolution.
                Our work is aiming to be an extension of <font color="CCCC00">Active SLAM</font> with an efficient multisensor data fusion model to allow <font color="427af4">accurate mapping</font>, <font color="427af4">global loop closure</font> and <font color="427af4">large-scale online SLAM</font> for challenging and complicated environment.
							<br>
							</p>
							<p style="margin-left: 43%; margin-top: 1em">
							<font color="49bf9d">Zhekai Jin</font>, Yifei Shao, Minjoon So, Carl Sable, Neveen Shlayan<br>
							<i>IEEE Intelligent Transportation Systems Conference (ITSC) 2019</i><br>
							<font color="4e79a7"><i>&#9733; 1st Place in the IEEE Region 1 2019 Student Papers Competition &#9733;</i></font><br>
								<a href="https://engfac.cooper.edu/nshlayan/690">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="docs/IEEE_Region_One_Submission.pdf">PDF(Draft)</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="docs/Semiyear_Report.pdf">Report</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://github.com/ZhekaiJin/the-Cooper-Mapper">Code (Github)</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://docs.google.com/presentation/d/1sPrlTF6rTZLBEbeD54hqItPvx9GTtTAkng0VJ8XbQQk/edit?usp=sharing">SLAM in 5 MINS</a>
							</p>
						</article>
						<article class="12u 12u$(xsmall) work-item">
							<a href="https://github.com/ZhekaiJin/VR-TELE" class="image fit thumb left"><img src="images/projects/vr.jpg" alt="" /></a>
							<h3 style="margin-left: 43%">VR-TELE: Realization of 3D Telepresence with HTC Vive and Raspberry Pi</h3>
							<p style="margin-left: 43%">
								This project aims to build a realization of the abstract idea “3D Telepresence” by the aid of microcontroller (Raspberry Pi) and the Head Mounted Display ( HTC Vive) and additional hardware.
								The idea is to make a wireless connected robot platform, mimicking the observer’s perspective to capture its ambient environment and feeding it into observer’s HMD, which therefore allows the observer to fully perceive device’s surrounding as if he or she is in the device’s position.
								A real scale environment of the robot is reconstructed to the user, with the user's motion reflected on the mobile device in real time.
								The applications of this work range from basic tasks like monitoring to highly expendable functions like bomb disposal.
								My work involves stages of web development, time-constrained <font color="CCCC00">pose estimation</font>,
								efficient <font color="CCCC00">3D metric map representations</font>, <font color="CCCC00">stereo SLAM</font>, and data transmission & encryption.
							<br>
							</p>
							<p style="margin-left: 43%; margin-top: 1em">
							Principal Investigator: Dr. Neveen Shlayan <br>
							<font color="49bf9d">Zhekai Jin</font>, Simon Shao, and Rafi Mueen<br>
								<a href="https://engfac.cooper.edu/nshlayan/692">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://github.com/ZhekaiJin/VR-TELE">Partial code release (Github)</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="docs/TELE.pdf">Hardware Setup Guide</a>
							</p>
						</article>
						<article class="12u 12u$(xsmall) work-item">
							<a href="http://www.utrc2.org/research/projects/real-time-estimation-transit-origin" class="image fit thumb left"><img src="images/projects/iot.jpg" alt="" /></a>
							<h3 style="margin-left: 43%">The Cooper IoT: Generic Distributed IoT Platform for human traffic monitoring</h3>
							<p style="margin-left: 43%">
								We propose utilizing Bluetooth/WiFi technology to estimate origin-destination (OD) demands and station wait times of users of any public transportation system.
	              If the entrance and exit turnstiles at subway stations are equipped with Bluetooth/WiFi receivers,
	              it is possible to capture OD information for some percentage of the riders with visible Bluetooth/WiFi devices.
	              The riders who have electronic devices such as most cell phones, iPods, and computers carry unique information in their devices’ Bluetooth/WiFi MAC address.
	              This information can be used scrambled and used anonymously to detect the origin and destination of riders by matching data collected at entrances and exits from the system.
							<!-- This is an on-going study that explores the po-tential benefits of using pedestrian data for evaluation andenhancement of public transportation.
							We proposes the utilization of Bluetooth (BT) and WiFi technologiesto estimate time-dependent origin-destination (OD) demandsand station wait-times of transit bus and subway users.
							We also acquired some preliminary results from multiple pilot field studies, that were conducted at some of the major New YorkCity (NYC) public transportation facilities.
							The main objective of this study is to inquire into the various ways this extensive transit rider data can be used and to establish a general framework through data-driven pedestrian modeling
							within transit stations that renders estimation of key parameters and strategic control of public transportation services possible. -->
							I implemented real-time <font color="427af4">WiFi-and-Bluetooth-address-based position tracking</font> and <font color="427af4">human detection</font> algorithms to monitor <font color="CCCC00">human traffic flow</font> and performed <font color="427af4">time-series analysis</font> with a stochastic queuing model.
							<br>
							</p>
							<p style="margin-left: 43%; margin-top: 1em">
							Principal Investigator: Dr. Neveen Shlayan <br>
							<font color="49bf9d">Zhekai Jin</font>, Jialun Bao, and Rafi Mueen<br>
								<a href="https://engfac.cooper.edu/nshlayan/691">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://ieeexplore.ieee.org/document/7795559">Publication</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://trid.trb.org/view/1468647">Report</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
								<a href="https://github.com/ZhekaiJin/Cooper-IoT">Code (Github)</a>
							</p>
						</article>
						<article class="12u 12u$(xsmall) work-item">
							<a href="" class="image fit thumb left"><img src="images/projects/scan.jpg" alt="" /></a>
							<h3 style="margin-left: 43%">The Principles of MRI and Analysis of the Adoption of MRI in China</h3>
							<p style="margin-left: 43%">
								This work explores the technical principles of Magnetic Resonance Imaging (MRI), its medical applications and its particular usage in China.
	              I delved into the details of Nuclear Magnetic Resonance (NMR) technology with its relations to the MRI. Then I discussed the advantages and limitation of the MRI,
	              in close comparison to X-ray and computerized tomography (CT). And an insight into China's MRI usage is provided.
							<br>
							</p>
							<p style="margin-left: 43%; margin-top: 1em">
							Principal Investigator: <a href="https://academics.hamilton.edu/chemistry/faculty-kinnel">Dr. Robin Kinnel</a> <br>
							<font color="49bf9d">Zhekai Jin</font><br>
								<a href="docs/MRI.pdf">Menuscript</a>
							</p>
						</article>
					</div>
				</section>

				<section id="two">
					<h2>Personal Projects</h2>
					<div class="row">
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/01.jpg" class="image fit thumb"><img src="images/thumbs/01.jpg" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/AI-Checker">AI Checker with Minimax Algorithm</a></h3>
							<p>An implementation of Checker game using Minimax with Alpha Beta Pruning and Search Tree. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="videos/checker.mp4"> AI Checker in action</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/02.jpg" class="image fit thumb"><img src="images/thumbs/02.jpg" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/Artifical_NN">Artificial Nueral Network</a></h3>
							<p>An Implementation of Artificial Neural Network from scratch for Robotics Range Sensor classification.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/03.jpg" class="image fit thumb"><img src="images/thumbs/03.jpg" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/EventPlus">EventPlus</a></h3>
							<p>Event Search and Ticket Recommendation Service based on Java web service. &nbsp;&nbsp;&nbsp;<a href="https://zhekaijin.us">Website</a> (username:1111, password:2222)</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/04.jpg" class="image fit thumb"><img src="images/thumbs/04.jpg" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/pass2act">Pass2act</a></h3>
							<p>Passive Voice to Active Voice Article Converter.<a href="videos/pass2act.mp4"> Pass2act in action</a> <br>
								<font color="4e79a7"><i>&#9733;</i></font> : Rated Best NLP project of the year.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/05.jpg" class="image fit thumb"><img src="images/thumbs/05.jpg" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/Textcat">Textcat</a></h3>
							<p>Text categorization using Naive Bayes method with novel smoothing.
								<font color="4e79a7"><i>&#9733;</i></font> : Placed 3rd place among 107 classifers.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="images/fulls/06.gif" class="image fit thumb"><img src="images/thumbs/06.gif" alt="" /></a>
							<h3><a href="https://github.com/ZhekaiJin/Celestial-Mechanics-Application">Celestial Mechanics Application</a></h3>
							<p>Physics simulation deploying three-body model and four-body model to achieve a fuel-efficient spaceship trajectory.</p>
						</article>
					</div>

					<ul class="actions">
						<li><a href="https://github.com/zhekaijin" class="button">View them on Github!</a></li>
					</ul>
					</section>

					<section id="three">
					<h2>Time for some fun!</h2>
					Some command line games and projects to concept experimentations.
					<ul>
						  <li><a href="https://github.com/ZhekaiJin/NSA">NBA-Shot-Analysis; NBA Player Strength Visualization </a> (React)</li>
						  <li><a href="https://github.com/ZhekaiJin/Train-Ticket-Booking-System">command-line ticket search and booking system</a> (python)</li>
							<li><a href="https://github.com/ZhekaiJin/Practice-Projects/tree/master/Flappy_bird_C">command-line Flappy Bird</a> (C)</li>
							<li><a href="https://github.com/ZhekaiJin/Practice-Projects/tree/master/Snake_C">command-line Snake game</a> (C)</li>
							<li><a href="https://github.com/ZhekaiJin/Practice-Projects/tree/master/Tetris_python">Tetris game</a> (python)</li>
						  <li><a href="https://github.com/ZhekaiJin/Practice-Projects/tree/master/sokoban">Sokoban game</a> (python)</li>
							<li><a href="https://github.com/ZhekaiJin/Practice-Projects/tree/master/2Smallfind">command-line <font color="8AACE5">find</font> utility</a> (C) (Have duplicate files in your file system? This can help you get rid of them.)</li>

					</ul>
					<hr/>
					<p style="margin-bottom:0">
					<br>
					<sub>Design: <a href="http://html5up.net">HTML5 UP</a></sub>
					</p>
				</section>
		</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="copyright">
						<li>Meet <a href="https://en.wikipedia.org/wiki/Danbo_(character)">Danbo</a> the cardboard robot.</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
